[
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "My Projects",
    "section": "",
    "text": "A Replication of Karlan and List (2007)\n\n\n\n\n\n\nHaoxuan Li\n\n\nMay 7, 2025\n\n\n\n\n\n\n\n\n\n\n\nAI Stock Predictor\n\n\nUsing LSTM to forecast stock prices\n\n\n\n\n\n\nApr 23, 2025\n\n\n\n\n\n\n\n\n\n\n\nPoisson Regression Examples\n\n\n\n\n\n\nHaoxuan Li\n\n\nMay 7, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "projects/project1/index.html",
    "href": "projects/project1/index.html",
    "title": "AI Stock Predictor",
    "section": "",
    "text": "This project uses a recurrent neural network to predict stock prices based on historical time series data using LSTM models. Results show improved accuracy over traditional methods."
  },
  {
    "objectID": "projects/HW1/index.html",
    "href": "projects/HW1/index.html",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nThis project seeks to replicate their results.\n\n\n\nimport pandas as pd\n\n\ndf = pd.read_stata(\"C:/Users/ASUS/Downloads/karlan_list_2007.dta\")\n\ndf.head()\n\n\n\n\n\n\n\n\ntreatment\ncontrol\nratio\nratio2\nratio3\nsize\nsize25\nsize50\nsize100\nsizeno\n...\nredcty\nbluecty\npwhite\npblack\npage18_39\nave_hh_sz\nmedian_hhincome\npowner\npsch_atlstba\npop_propurban\n\n\n\n\n0\n0\n1\nControl\n0\n0\nControl\n0\n0\n0\n0\n...\n0.0\n1.0\n0.446493\n0.527769\n0.317591\n2.10\n28517.0\n0.499807\n0.324528\n1.0\n\n\n1\n0\n1\nControl\n0\n0\nControl\n0\n0\n0\n0\n...\n1.0\n0.0\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n2\n1\n0\n1\n0\n0\n$100,000\n0\n0\n1\n0\n...\n0.0\n1.0\n0.935706\n0.011948\n0.276128\n2.48\n51175.0\n0.721941\n0.192668\n1.0\n\n\n3\n1\n0\n1\n0\n0\nUnstated\n0\n0\n0\n1\n...\n1.0\n0.0\n0.888331\n0.010760\n0.279412\n2.65\n79269.0\n0.920431\n0.412142\n1.0\n\n\n4\n1\n0\n1\n0\n0\n$50,000\n0\n1\n0\n0\n...\n0.0\n1.0\n0.759014\n0.127421\n0.442389\n1.85\n40908.0\n0.416072\n0.439965\n1.0\n\n\n\n\n5 rows × 51 columns\n\n\n\n\n\n\n\n\n\nVariable Definitions\n\n\n\n\n\n\n# --- Basic summary of dataset ---\nprint(\"Dataset dimensions (rows x columns):\", df.shape)\n\n# --- Core outcome: 'gave' ---\nprint(\"\\nDistribution of 'gave' (percentage):\")\nprint(df['gave'].value_counts(normalize=True).round(3) * 100)\n\n# --- Core outcome: donation amount ---\nprint(\"\\nSummary statistics for 'amount' (donation):\")\nprint(df['amount'].describe())\n\n# --- Treatment group sizes ---\nprint(\"\\nTreatment group sizes:\")\nprint(df['treatment'].value_counts())\n\n\n# --- Match threshold sizes ---\nprint(\"\\nMatch threshold types:\")\nprint(df[['size25', 'size50', 'size100', 'sizeno']].sum())\n\n# --- Ask suggestion levels ---\nprint(\"\\nSuggested ask levels:\")\nprint(df[['askd1', 'askd2', 'askd3']].sum())\n\n# --- Donor history: frequency and recency ---\nprint(\"\\nPrior donation summary:\")\nprint(df[['freq', 'years', 'mrm2']].describe())\n\n# --- Demographics ---\nprint(\"\\nGender breakdown:\")\nprint(df['female'].value_counts())\n\nprint(\"\\nCouple vs individual:\")\nprint(df['couple'].value_counts())\n\n# --- Geographic: political environment ---\nprint(\"\\nRed vs Blue states:\")\nprint(df[['red0', 'blue0']].sum())\n\n# --- Missing value overview (first 15 columns) ---\nprint(\"\\nMissing values (first 15 variables):\")\nprint(df.iloc[:, :15].isna().sum())\n\nDataset dimensions (rows x columns): (50083, 51)\n\nDistribution of 'gave' (percentage):\ngave\n0    97.9\n1     2.1\nName: proportion, dtype: float64\n\nSummary statistics for 'amount' (donation):\ncount    50083.000000\nmean         0.915694\nstd          8.709199\nmin          0.000000\n25%          0.000000\n50%          0.000000\n75%          0.000000\nmax        400.000000\nName: amount, dtype: float64\n\nTreatment group sizes:\ntreatment\n1    33396\n0    16687\nName: count, dtype: int64\n\nMatch threshold types:\nsize25     8350\nsize50     8345\nsize100    8350\nsizeno     8351\ndtype: int64\n\nSuggested ask levels:\naskd1    11134\naskd2    11133\naskd3    11129\ndtype: int64\n\nPrior donation summary:\n               freq         years          mrm2\ncount  50083.000000  50082.000000  50082.000000\nmean       8.039355      6.097540     13.007268\nstd       11.394454      5.503492     12.081403\nmin        0.000000      0.000000      0.000000\n25%        2.000000      2.000000      4.000000\n50%        4.000000      5.000000      8.000000\n75%       10.000000      9.000000     19.000000\nmax      218.000000     95.000000    168.000000\n\nGender breakdown:\nfemale\n0.0    35374\n1.0    13598\nName: count, dtype: int64\n\nCouple vs individual:\ncouple\n0.0    44438\n1.0     4497\nName: count, dtype: int64\n\nRed vs Blue states:\nred0     20242.0\nblue0    29806.0\ndtype: float64\n\nMissing values (first 15 variables):\ntreatment    0\ncontrol      0\nratio        0\nratio2       0\nratio3       0\nsize         0\nsize25       0\nsize50       0\nsize100      0\nsizeno       0\nask          0\naskd1        0\naskd2        0\naskd3        0\nask1         0\ndtype: int64\n\n\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\ntreatment\nTreatment\n\n\ncontrol\nControl\n\n\nratio\nMatch ratio\n\n\nratio2\n2:1 match ratio\n\n\nratio3\n3:1 match ratio\n\n\nsize\nMatch threshold\n\n\nsize25\n$25,000 match threshold\n\n\nsize50\n$50,000 match threshold\n\n\nsize100\n$100,000 match threshold\n\n\nsizeno\nUnstated match threshold\n\n\nask\nSuggested donation amount\n\n\naskd1\nSuggested donation was highest previous contribution\n\n\naskd2\nSuggested donation was 1.25 x highest previous contribution\n\n\naskd3\nSuggested donation was 1.50 x highest previous contribution\n\n\nask1\nHighest previous contribution (for suggestion)\n\n\nask2\n1.25 x highest previous contribution (for suggestion)\n\n\nask3\n1.50 x highest previous contribution (for suggestion)\n\n\namount\nDollars given\n\n\ngave\nGave anything\n\n\namountchange\nChange in amount given\n\n\nhpa\nHighest previous contribution\n\n\nltmedmra\nSmall prior donor: last gift was less than median $35\n\n\nfreq\nNumber of prior donations\n\n\nyears\nNumber of years since initial donation\n\n\nyear5\nAt least 5 years since initial donation\n\n\nmrm2\nNumber of months since last donation\n\n\ndormant\nAlready donated in 2005\n\n\nfemale\nFemale\n\n\ncouple\nCouple\n\n\nstate50one\nState tag: 1 for one observation of each of 50 states; 0 otherwise\n\n\nnonlit\nNonlitigation\n\n\ncases\nCourt cases from state in 2004-5 in which organization was involved\n\n\nstatecnt\nPercent of sample from state\n\n\nstateresponse\nProportion of sample from the state who gave\n\n\nstateresponset\nProportion of treated sample from the state who gave\n\n\nstateresponsec\nProportion of control sample from the state who gave\n\n\nstateresponsetminc\nstateresponset - stateresponsec\n\n\nperbush\nState vote share for Bush\n\n\nclose25\nState vote share for Bush between 47.5% and 52.5%\n\n\nred0\nRed state\n\n\nblue0\nBlue state\n\n\nredcty\nRed county\n\n\nbluecty\nBlue county\n\n\npwhite\nProportion white within zip code\n\n\npblack\nProportion black within zip code\n\n\npage18_39\nProportion age 18-39 within zip code\n\n\nave_hh_sz\nAverage household size within zip code\n\n\nmedian_hhincome\nMedian household income within zip code\n\n\npowner\nProportion house owner within zip code\n\n\npsch_atlstba\nProportion who finished college within zip code\n\n\npop_propurban\nProportion of population urban within zip code\n\n\n\n\n\n\n\n# --- Basic summary of dataset ---\nprint(\"Dataset dimensions (rows x columns):\", df.shape)\n\n# --- Core outcome: 'gave' ---\nprint(\"\\nDistribution of 'gave' (percentage):\")\nprint(df['gave'].value_counts(normalize=True).round(3) * 100)\n\n# --- Core outcome: donation amount ---\nprint(\"\\nSummary statistics for 'amount' (donation):\")\nprint(df['amount'].describe())\n\n# --- Treatment group sizes ---\nprint(\"\\nTreatment group sizes:\")\nprint(df['treatment'].value_counts())\n\n\n# --- Match threshold sizes ---\nprint(\"\\nMatch threshold types:\")\nprint(df[['size25', 'size50', 'size100', 'sizeno']].sum())\n\n# --- Ask suggestion levels ---\nprint(\"\\nSuggested ask levels:\")\nprint(df[['askd1', 'askd2', 'askd3']].sum())\n\n# --- Donor history: frequency and recency ---\nprint(\"\\nPrior donation summary:\")\nprint(df[['freq', 'years', 'mrm2']].describe())\n\n# --- Demographics ---\nprint(\"\\nGender breakdown:\")\nprint(df['female'].value_counts())\n\nprint(\"\\nCouple vs individual:\")\nprint(df['couple'].value_counts())\n\n# --- Geographic: political environment ---\nprint(\"\\nRed vs Blue states:\")\nprint(df[['red0', 'blue0']].sum())\n\n# --- Missing value overview (first 15 columns) ---\nprint(\"\\nMissing values (first 15 variables):\")\nprint(df.iloc[:, :15].isna().sum())\n\nDataset dimensions (rows x columns): (50083, 51)\n\nDistribution of 'gave' (percentage):\ngave\n0    97.9\n1     2.1\nName: proportion, dtype: float64\n\nSummary statistics for 'amount' (donation):\ncount    50083.000000\nmean         0.915694\nstd          8.709199\nmin          0.000000\n25%          0.000000\n50%          0.000000\n75%          0.000000\nmax        400.000000\nName: amount, dtype: float64\n\nTreatment group sizes:\ntreatment\n1    33396\n0    16687\nName: count, dtype: int64\n\nMatch threshold types:\nsize25     8350\nsize50     8345\nsize100    8350\nsizeno     8351\ndtype: int64\n\nSuggested ask levels:\naskd1    11134\naskd2    11133\naskd3    11129\ndtype: int64\n\nPrior donation summary:\n               freq         years          mrm2\ncount  50083.000000  50082.000000  50082.000000\nmean       8.039355      6.097540     13.007268\nstd       11.394454      5.503492     12.081403\nmin        0.000000      0.000000      0.000000\n25%        2.000000      2.000000      4.000000\n50%        4.000000      5.000000      8.000000\n75%       10.000000      9.000000     19.000000\nmax      218.000000     95.000000    168.000000\n\nGender breakdown:\nfemale\n0.0    35374\n1.0    13598\nName: count, dtype: int64\n\nCouple vs individual:\ncouple\n0.0    44438\n1.0     4497\nName: count, dtype: int64\n\nRed vs Blue states:\nred0     20242.0\nblue0    29806.0\ndtype: float64\n\nMissing values (first 15 variables):\ntreatment    0\ncontrol      0\nratio        0\nratio2       0\nratio3       0\nsize         0\nsize25       0\nsize50       0\nsize100      0\nsizeno       0\nask          0\naskd1        0\naskd2        0\naskd3        0\nask1         0\ndtype: int64\n\n\n\n\n\nAs an ad hoc test of the randomization mechanism, I provide a series of tests that compare aspects of the treatment and control groups to assess whether they are statistically significantly different from one another.\n\nimport scipy.stats as stats\nimport statsmodels.api as sm\nimport statsmodels.formula.api as smf\n\n\nvar = 'mrm2'\n\ntreated = df[df['treatment'] == 1][var].dropna()\ncontrol = df[df['treatment'] == 0][var].dropna()\n\nt_stat, p_val = stats.ttest_ind(treated, control, equal_var=False)\nprint(f\"t-test for {var}:\")\nprint(f\"t = {t_stat:.3f}, p = {p_val:.4f}\")\n\nmodel = smf.ols(f\"{var} ~ treatment\", data=df).fit()\nprint(f\"\\nLinear regression for {var} ~ treatment:\")\nprint(model.summary().tables[1])\n...\n\nt-test for mrm2:\nt = 0.120, p = 0.9049\n\nLinear regression for mrm2 ~ treatment:\n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nIntercept     12.9981      0.094    138.979      0.000      12.815      13.181\ntreatment      0.0137      0.115      0.119      0.905      -0.211       0.238\n==============================================================================\n\n\nEllipsis\n\n\n\n\n\nTo verify that random assignment was successful, we compare several non-outcome variables between the treatment and control groups.\nWe begin with mrm2, which represents the number of months since the last donation. Using both a t-test and a simple linear regression, we find no statistically significant difference between the groups:\n\nThe t-test yields t = 0.120, p = 0.905.\nThe regression coefficient on the treatment indicator is 0.014 (p = 0.905).\n\nThis confirms the results are consistent across both methods, as expected. These findings support the randomization validity and are in line with Table 1 in Karlan & List (2007), which demonstrates that observable donor characteristics are well balanced across experimental arms.\n\nvar = 'years'\n\n\ntreated = df[df['treatment'] == 1][var].dropna()\ncontrol = df[df['treatment'] == 0][var].dropna()\n\n\nt_stat, p_val = stats.ttest_ind(treated, control, equal_var=False)\nprint(f\"t-test for {var}:\")\nprint(f\"t = {t_stat:.3f}, p = {p_val:.4f}\")\n\n\nmodel = smf.ols(f\"{var} ~ treatment\", data=df).fit()\nprint(f\"\\nLinear regression for {var} ~ treatment:\")\nprint(model.summary().tables[1])\n\nt-test for years:\nt = -1.091, p = 0.2753\n\nLinear regression for years ~ treatment:\n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nIntercept      6.1359      0.043    144.023      0.000       6.052       6.219\ntreatment     -0.0575      0.052     -1.103      0.270      -0.160       0.045\n==============================================================================\n\n\nWe next test for balance on the variable years, which measures the number of years since the individual’s first donation.\n\nThe independent samples t-test yields t = -1.091 with p = 0.275, indicating no significant difference.\nA linear regression of years on the treatment indicator produces a coefficient of -0.0575 (p = 0.270).\n\nBoth methods confirm that this variable is well balanced across treatment and control groups. This result is consistent with Table 1 in Karlan & List (2007), and supports the success of the random assignment procedure."
  },
  {
    "objectID": "projects/HW1/index.html#introduction",
    "href": "projects/HW1/index.html#introduction",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nThis project seeks to replicate their results.\n\n\n\nimport pandas as pd\n\n\ndf = pd.read_stata(\"C:/Users/ASUS/Downloads/karlan_list_2007.dta\")\n\ndf.head()\n\n\n\n\n\n\n\n\ntreatment\ncontrol\nratio\nratio2\nratio3\nsize\nsize25\nsize50\nsize100\nsizeno\n...\nredcty\nbluecty\npwhite\npblack\npage18_39\nave_hh_sz\nmedian_hhincome\npowner\npsch_atlstba\npop_propurban\n\n\n\n\n0\n0\n1\nControl\n0\n0\nControl\n0\n0\n0\n0\n...\n0.0\n1.0\n0.446493\n0.527769\n0.317591\n2.10\n28517.0\n0.499807\n0.324528\n1.0\n\n\n1\n0\n1\nControl\n0\n0\nControl\n0\n0\n0\n0\n...\n1.0\n0.0\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n2\n1\n0\n1\n0\n0\n$100,000\n0\n0\n1\n0\n...\n0.0\n1.0\n0.935706\n0.011948\n0.276128\n2.48\n51175.0\n0.721941\n0.192668\n1.0\n\n\n3\n1\n0\n1\n0\n0\nUnstated\n0\n0\n0\n1\n...\n1.0\n0.0\n0.888331\n0.010760\n0.279412\n2.65\n79269.0\n0.920431\n0.412142\n1.0\n\n\n4\n1\n0\n1\n0\n0\n$50,000\n0\n1\n0\n0\n...\n0.0\n1.0\n0.759014\n0.127421\n0.442389\n1.85\n40908.0\n0.416072\n0.439965\n1.0\n\n\n\n\n5 rows × 51 columns\n\n\n\n\n\n\n\n\n\nVariable Definitions\n\n\n\n\n\n\n# --- Basic summary of dataset ---\nprint(\"Dataset dimensions (rows x columns):\", df.shape)\n\n# --- Core outcome: 'gave' ---\nprint(\"\\nDistribution of 'gave' (percentage):\")\nprint(df['gave'].value_counts(normalize=True).round(3) * 100)\n\n# --- Core outcome: donation amount ---\nprint(\"\\nSummary statistics for 'amount' (donation):\")\nprint(df['amount'].describe())\n\n# --- Treatment group sizes ---\nprint(\"\\nTreatment group sizes:\")\nprint(df['treatment'].value_counts())\n\n\n# --- Match threshold sizes ---\nprint(\"\\nMatch threshold types:\")\nprint(df[['size25', 'size50', 'size100', 'sizeno']].sum())\n\n# --- Ask suggestion levels ---\nprint(\"\\nSuggested ask levels:\")\nprint(df[['askd1', 'askd2', 'askd3']].sum())\n\n# --- Donor history: frequency and recency ---\nprint(\"\\nPrior donation summary:\")\nprint(df[['freq', 'years', 'mrm2']].describe())\n\n# --- Demographics ---\nprint(\"\\nGender breakdown:\")\nprint(df['female'].value_counts())\n\nprint(\"\\nCouple vs individual:\")\nprint(df['couple'].value_counts())\n\n# --- Geographic: political environment ---\nprint(\"\\nRed vs Blue states:\")\nprint(df[['red0', 'blue0']].sum())\n\n# --- Missing value overview (first 15 columns) ---\nprint(\"\\nMissing values (first 15 variables):\")\nprint(df.iloc[:, :15].isna().sum())\n\nDataset dimensions (rows x columns): (50083, 51)\n\nDistribution of 'gave' (percentage):\ngave\n0    97.9\n1     2.1\nName: proportion, dtype: float64\n\nSummary statistics for 'amount' (donation):\ncount    50083.000000\nmean         0.915694\nstd          8.709199\nmin          0.000000\n25%          0.000000\n50%          0.000000\n75%          0.000000\nmax        400.000000\nName: amount, dtype: float64\n\nTreatment group sizes:\ntreatment\n1    33396\n0    16687\nName: count, dtype: int64\n\nMatch threshold types:\nsize25     8350\nsize50     8345\nsize100    8350\nsizeno     8351\ndtype: int64\n\nSuggested ask levels:\naskd1    11134\naskd2    11133\naskd3    11129\ndtype: int64\n\nPrior donation summary:\n               freq         years          mrm2\ncount  50083.000000  50082.000000  50082.000000\nmean       8.039355      6.097540     13.007268\nstd       11.394454      5.503492     12.081403\nmin        0.000000      0.000000      0.000000\n25%        2.000000      2.000000      4.000000\n50%        4.000000      5.000000      8.000000\n75%       10.000000      9.000000     19.000000\nmax      218.000000     95.000000    168.000000\n\nGender breakdown:\nfemale\n0.0    35374\n1.0    13598\nName: count, dtype: int64\n\nCouple vs individual:\ncouple\n0.0    44438\n1.0     4497\nName: count, dtype: int64\n\nRed vs Blue states:\nred0     20242.0\nblue0    29806.0\ndtype: float64\n\nMissing values (first 15 variables):\ntreatment    0\ncontrol      0\nratio        0\nratio2       0\nratio3       0\nsize         0\nsize25       0\nsize50       0\nsize100      0\nsizeno       0\nask          0\naskd1        0\naskd2        0\naskd3        0\nask1         0\ndtype: int64\n\n\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\ntreatment\nTreatment\n\n\ncontrol\nControl\n\n\nratio\nMatch ratio\n\n\nratio2\n2:1 match ratio\n\n\nratio3\n3:1 match ratio\n\n\nsize\nMatch threshold\n\n\nsize25\n$25,000 match threshold\n\n\nsize50\n$50,000 match threshold\n\n\nsize100\n$100,000 match threshold\n\n\nsizeno\nUnstated match threshold\n\n\nask\nSuggested donation amount\n\n\naskd1\nSuggested donation was highest previous contribution\n\n\naskd2\nSuggested donation was 1.25 x highest previous contribution\n\n\naskd3\nSuggested donation was 1.50 x highest previous contribution\n\n\nask1\nHighest previous contribution (for suggestion)\n\n\nask2\n1.25 x highest previous contribution (for suggestion)\n\n\nask3\n1.50 x highest previous contribution (for suggestion)\n\n\namount\nDollars given\n\n\ngave\nGave anything\n\n\namountchange\nChange in amount given\n\n\nhpa\nHighest previous contribution\n\n\nltmedmra\nSmall prior donor: last gift was less than median $35\n\n\nfreq\nNumber of prior donations\n\n\nyears\nNumber of years since initial donation\n\n\nyear5\nAt least 5 years since initial donation\n\n\nmrm2\nNumber of months since last donation\n\n\ndormant\nAlready donated in 2005\n\n\nfemale\nFemale\n\n\ncouple\nCouple\n\n\nstate50one\nState tag: 1 for one observation of each of 50 states; 0 otherwise\n\n\nnonlit\nNonlitigation\n\n\ncases\nCourt cases from state in 2004-5 in which organization was involved\n\n\nstatecnt\nPercent of sample from state\n\n\nstateresponse\nProportion of sample from the state who gave\n\n\nstateresponset\nProportion of treated sample from the state who gave\n\n\nstateresponsec\nProportion of control sample from the state who gave\n\n\nstateresponsetminc\nstateresponset - stateresponsec\n\n\nperbush\nState vote share for Bush\n\n\nclose25\nState vote share for Bush between 47.5% and 52.5%\n\n\nred0\nRed state\n\n\nblue0\nBlue state\n\n\nredcty\nRed county\n\n\nbluecty\nBlue county\n\n\npwhite\nProportion white within zip code\n\n\npblack\nProportion black within zip code\n\n\npage18_39\nProportion age 18-39 within zip code\n\n\nave_hh_sz\nAverage household size within zip code\n\n\nmedian_hhincome\nMedian household income within zip code\n\n\npowner\nProportion house owner within zip code\n\n\npsch_atlstba\nProportion who finished college within zip code\n\n\npop_propurban\nProportion of population urban within zip code\n\n\n\n\n\n\n\n# --- Basic summary of dataset ---\nprint(\"Dataset dimensions (rows x columns):\", df.shape)\n\n# --- Core outcome: 'gave' ---\nprint(\"\\nDistribution of 'gave' (percentage):\")\nprint(df['gave'].value_counts(normalize=True).round(3) * 100)\n\n# --- Core outcome: donation amount ---\nprint(\"\\nSummary statistics for 'amount' (donation):\")\nprint(df['amount'].describe())\n\n# --- Treatment group sizes ---\nprint(\"\\nTreatment group sizes:\")\nprint(df['treatment'].value_counts())\n\n\n# --- Match threshold sizes ---\nprint(\"\\nMatch threshold types:\")\nprint(df[['size25', 'size50', 'size100', 'sizeno']].sum())\n\n# --- Ask suggestion levels ---\nprint(\"\\nSuggested ask levels:\")\nprint(df[['askd1', 'askd2', 'askd3']].sum())\n\n# --- Donor history: frequency and recency ---\nprint(\"\\nPrior donation summary:\")\nprint(df[['freq', 'years', 'mrm2']].describe())\n\n# --- Demographics ---\nprint(\"\\nGender breakdown:\")\nprint(df['female'].value_counts())\n\nprint(\"\\nCouple vs individual:\")\nprint(df['couple'].value_counts())\n\n# --- Geographic: political environment ---\nprint(\"\\nRed vs Blue states:\")\nprint(df[['red0', 'blue0']].sum())\n\n# --- Missing value overview (first 15 columns) ---\nprint(\"\\nMissing values (first 15 variables):\")\nprint(df.iloc[:, :15].isna().sum())\n\nDataset dimensions (rows x columns): (50083, 51)\n\nDistribution of 'gave' (percentage):\ngave\n0    97.9\n1     2.1\nName: proportion, dtype: float64\n\nSummary statistics for 'amount' (donation):\ncount    50083.000000\nmean         0.915694\nstd          8.709199\nmin          0.000000\n25%          0.000000\n50%          0.000000\n75%          0.000000\nmax        400.000000\nName: amount, dtype: float64\n\nTreatment group sizes:\ntreatment\n1    33396\n0    16687\nName: count, dtype: int64\n\nMatch threshold types:\nsize25     8350\nsize50     8345\nsize100    8350\nsizeno     8351\ndtype: int64\n\nSuggested ask levels:\naskd1    11134\naskd2    11133\naskd3    11129\ndtype: int64\n\nPrior donation summary:\n               freq         years          mrm2\ncount  50083.000000  50082.000000  50082.000000\nmean       8.039355      6.097540     13.007268\nstd       11.394454      5.503492     12.081403\nmin        0.000000      0.000000      0.000000\n25%        2.000000      2.000000      4.000000\n50%        4.000000      5.000000      8.000000\n75%       10.000000      9.000000     19.000000\nmax      218.000000     95.000000    168.000000\n\nGender breakdown:\nfemale\n0.0    35374\n1.0    13598\nName: count, dtype: int64\n\nCouple vs individual:\ncouple\n0.0    44438\n1.0     4497\nName: count, dtype: int64\n\nRed vs Blue states:\nred0     20242.0\nblue0    29806.0\ndtype: float64\n\nMissing values (first 15 variables):\ntreatment    0\ncontrol      0\nratio        0\nratio2       0\nratio3       0\nsize         0\nsize25       0\nsize50       0\nsize100      0\nsizeno       0\nask          0\naskd1        0\naskd2        0\naskd3        0\nask1         0\ndtype: int64\n\n\n\n\n\nAs an ad hoc test of the randomization mechanism, I provide a series of tests that compare aspects of the treatment and control groups to assess whether they are statistically significantly different from one another.\n\nimport scipy.stats as stats\nimport statsmodels.api as sm\nimport statsmodels.formula.api as smf\n\n\nvar = 'mrm2'\n\ntreated = df[df['treatment'] == 1][var].dropna()\ncontrol = df[df['treatment'] == 0][var].dropna()\n\nt_stat, p_val = stats.ttest_ind(treated, control, equal_var=False)\nprint(f\"t-test for {var}:\")\nprint(f\"t = {t_stat:.3f}, p = {p_val:.4f}\")\n\nmodel = smf.ols(f\"{var} ~ treatment\", data=df).fit()\nprint(f\"\\nLinear regression for {var} ~ treatment:\")\nprint(model.summary().tables[1])\n...\n\nt-test for mrm2:\nt = 0.120, p = 0.9049\n\nLinear regression for mrm2 ~ treatment:\n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nIntercept     12.9981      0.094    138.979      0.000      12.815      13.181\ntreatment      0.0137      0.115      0.119      0.905      -0.211       0.238\n==============================================================================\n\n\nEllipsis\n\n\n\n\n\nTo verify that random assignment was successful, we compare several non-outcome variables between the treatment and control groups.\nWe begin with mrm2, which represents the number of months since the last donation. Using both a t-test and a simple linear regression, we find no statistically significant difference between the groups:\n\nThe t-test yields t = 0.120, p = 0.905.\nThe regression coefficient on the treatment indicator is 0.014 (p = 0.905).\n\nThis confirms the results are consistent across both methods, as expected. These findings support the randomization validity and are in line with Table 1 in Karlan & List (2007), which demonstrates that observable donor characteristics are well balanced across experimental arms.\n\nvar = 'years'\n\n\ntreated = df[df['treatment'] == 1][var].dropna()\ncontrol = df[df['treatment'] == 0][var].dropna()\n\n\nt_stat, p_val = stats.ttest_ind(treated, control, equal_var=False)\nprint(f\"t-test for {var}:\")\nprint(f\"t = {t_stat:.3f}, p = {p_val:.4f}\")\n\n\nmodel = smf.ols(f\"{var} ~ treatment\", data=df).fit()\nprint(f\"\\nLinear regression for {var} ~ treatment:\")\nprint(model.summary().tables[1])\n\nt-test for years:\nt = -1.091, p = 0.2753\n\nLinear regression for years ~ treatment:\n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nIntercept      6.1359      0.043    144.023      0.000       6.052       6.219\ntreatment     -0.0575      0.052     -1.103      0.270      -0.160       0.045\n==============================================================================\n\n\nWe next test for balance on the variable years, which measures the number of years since the individual’s first donation.\n\nThe independent samples t-test yields t = -1.091 with p = 0.275, indicating no significant difference.\nA linear regression of years on the treatment indicator produces a coefficient of -0.0575 (p = 0.270).\n\nBoth methods confirm that this variable is well balanced across treatment and control groups. This result is consistent with Table 1 in Karlan & List (2007), and supports the success of the random assignment procedure."
  },
  {
    "objectID": "projects/HW1/index.html#experimental-results",
    "href": "projects/HW1/index.html#experimental-results",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Experimental Results",
    "text": "Experimental Results\n\nCharitable Contribution Made\nFirst, I analyze whether matched donations lead to an increased response rate of making a donation.\n\nimport matplotlib.pyplot as plt\n\ndonation_rate = df.groupby('treatment')['gave'].mean()\n\n\ndonation_rate.plot(kind='bar')\nplt.xticks([0, 1], ['Control', 'Treatment'], rotation=0)\nplt.title(\"Donation Rate by Treatment Group\")\nplt.ylabel(\"Proportion who donated\")\nplt.show()\n\n\n\n\n\n\n\n\n\ntreated = df[df['treatment'] == 1]['gave']\ncontrol = df[df['treatment'] == 0]['gave']\n\n\nt_stat, p_val = stats.ttest_ind(treated, control, equal_var=False)\nprint(f\"t-test for gave: t = {t_stat:.3f}, p = {p_val:.4f}\")\n\n\nmodel_linear = smf.ols(\"gave ~ treatment\", data=df).fit()\nprint(\"\\nLinear regression result:\")\nprint(model_linear.summary().tables[1])\n\nt-test for gave: t = 3.209, p = 0.0013\n\nLinear regression result:\n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nIntercept      0.0179      0.001     16.225      0.000       0.016       0.020\ntreatment      0.0042      0.001      3.101      0.002       0.002       0.007\n==============================================================================\n\n\n\nmodel_probit = smf.probit(\"gave ~ treatment\", data=df).fit()\nprint(\"\\nProbit regression result:\")\nprint(model_probit.summary().tables[1])\n\nOptimization terminated successfully.\n         Current function value: 0.100443\n         Iterations 7\n\nProbit regression result:\n==============================================================================\n                 coef    std err          z      P&gt;|z|      [0.025      0.975]\n------------------------------------------------------------------------------\nIntercept     -2.1001      0.023    -90.073      0.000      -2.146      -2.054\ntreatment      0.0868      0.028      3.113      0.002       0.032       0.141\n==============================================================================\n\n\n\n\nCharitable Contribution Made\nWe examine whether offering a matching donation increases the likelihood of charitable giving. First, we create a bar plot comparing the donation rates between the treatment and control groups. The treatment group exhibits a higher response rate (2.21%) compared to the control group (1.79%).\nTo formally test the difference, we conduct a t-test and a bivariate linear regression. The t-test yields a statistically significant result (t = 3.209, p = 0.0013), indicating that the difference in donation rates is unlikely to be due to chance. The regression confirms this finding, showing that the treatment increases the probability of giving by 0.42 percentage points (p = 0.002).\nWe further estimate a probit model to mirror Table 3, column 1 of Karlan and List (2007). The probit regression yields a treatment coefficient of 0.0868 (p = 0.002), confirming that assignment to the matching treatment significantly increases the likelihood of donation.\nThese results support the paper’s main finding: merely mentioning that a donation will be matched is enough to boost giving behavior. This highlights the power of framing and suggests that perceived leverage or impact motivates donors.\n\n\nDifferences between Match Rates\nNext, I assess the effectiveness of different sizes of matched donations on the response rate.\n\ngave_11 = df[(df['ratio2'] == 0) & (df['ratio3'] == 0)]['gave']\ngave_21 = df[df['ratio2'] == 1]['gave']\ngave_31 = df[df['ratio3'] == 1]['gave']\n\n\nprint(\"T-tests comparing match ratios:\")\nt1, p1 = stats.ttest_ind(gave_11, gave_21, equal_var=False)\nprint(f\"1:1 vs 2:1  --&gt; t = {t1:.3f}, p = {p1:.4f}\")\n\nt2, p2 = stats.ttest_ind(gave_21, gave_31, equal_var=False)\nprint(f\"2:1 vs 3:1  --&gt; t = {t2:.3f}, p = {p2:.4f}\")\n\n\nmodel = smf.ols(\"gave ~ ratio2 + ratio3\", data=df).fit()\nprint(\"\\nLinear regression for match ratios:\")\nprint(model.summary().tables[1])\n\n\nrate_11 = gave_11.mean()\nrate_21 = gave_21.mean()\nrate_31 = gave_31.mean()\nprint(\"\\nResponse rate differences:\")\nprint(f\"2:1 - 1:1 = {rate_21 - rate_11:.4f}\")\nprint(f\"3:1 - 2:1 = {rate_31 - rate_21:.4f}\")\n\nT-tests comparing match ratios:\n1:1 vs 2:1  --&gt; t = -2.220, p = 0.0265\n2:1 vs 3:1  --&gt; t = -0.050, p = 0.9600\n\nLinear regression for match ratios:\n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nIntercept      0.0190      0.001     22.306      0.000       0.017       0.021\nratio2         0.0036      0.002      2.269      0.023       0.000       0.007\nratio3         0.0037      0.002      2.332      0.020       0.001       0.007\n==============================================================================\n\nResponse rate differences:\n2:1 - 1:1 = 0.0036\n3:1 - 2:1 = 0.0001\n\n\nWe evaluate whether higher match ratios increase the likelihood of donating. The 1:1 match rate serves as the baseline.\nFirst, using a t-test, we find a statistically significant increase in donation likelihood when moving from a 1:1 to a 2:1 match (p = 0.0265), but no significant difference between 2:1 and 3:1 (p = 0.9600).\nA regression of the binary outcome gave on match ratio indicators confirms this. The coefficients on ratio2 and ratio3 are 0.0036 and 0.0037, respectively, both significant at the 5% level. This suggests that increasing the match rate from 1:1 to 2:1 increases the probability of donation by roughly 0.36 percentage points. However, moving from 2:1 to 3:1 yields virtually no further increase.\nThese findings support the interpretation on page 8 of Karlan and List (2007): while match offers boost giving, larger match ratios do not meaningfully outperform the simple 1:1 match.\n\n\nSize of Charitable Contribution\nIn this subsection, I analyze the effect of the size of matched donation on the size of the charitable contribution.\n\nmodel_all = smf.ols(\"amount ~ treatment\", data=df).fit()\nprint(\"Regression on full sample:\")\nprint(model_all.summary().tables[1])\n\nRegression on full sample:\n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nIntercept      0.8133      0.067     12.063      0.000       0.681       0.945\ntreatment      0.1536      0.083      1.861      0.063      -0.008       0.315\n==============================================================================\n\n\ntodo: now limit the data to just people who made a donation and repeat the previous analysis. This regression allows you to analyze how much respondents donate conditional on donating some positive amount. Interpret the regression coefficients – what did we learn? Does the treatment coefficient have a causal interpretation?\n\ndf_positive = df[df['amount'] &gt; 0]\nmodel_donors = smf.ols(\"amount ~ treatment\", data=df_positive).fit()\nprint(\"\\nRegression on donors only:\")\nprint(model_donors.summary().tables[1])\n\n\nRegression on donors only:\n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nIntercept     45.5403      2.423     18.792      0.000      40.785      50.296\ntreatment     -1.6684      2.872     -0.581      0.561      -7.305       3.968\n==============================================================================\n\n\ntodo: Make two plot: one for the treatment group and one for the control. Each plot should be a histogram of the donation amounts only among people who donated. Add a red vertical bar or some other annotation to indicate the sample average for each plot.\n\nimport matplotlib.pyplot as plt\n\n# Donation histograms for treatment and control (positive donations only)\nfig, axs = plt.subplots(1, 2, figsize=(12, 5), sharey=True)\n\nfor i, group in enumerate([0, 1]):\n    subset = df[(df['treatment'] == group) & (df['amount'] &gt; 0)]['amount']\n    axs[i].hist(subset, bins=30, alpha=0.7)\n    axs[i].axvline(subset.mean(), color='red', linestyle='dashed', linewidth=2)\n    axs[i].set_title(f\"{'Control' if group == 0 else 'Treatment'} Group\")\n    axs[i].set_xlabel(\"Donation Amount\")\n    axs[i].set_ylabel(\"Number of Donors\")\n\nplt.suptitle(\"Donation Amounts among Donors\")\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\nSize of Charitable Contribution\nWe assess whether the treatment affected not just the likelihood of giving, but also the size of donations.\nWe first estimate a regression on the full sample, including those who gave zero. The coefficient on treatment is 0.1536 (p = 0.063), suggesting that the match treatment may have slightly increased average donations, though the effect is marginally insignificant at the 5% level.\nWhen restricting the sample to only those who donated (i.e., positive donation amounts), we find a treatment coefficient of -1.67 (p = 0.561), indicating no significant difference in donation size among donors. This is consistent with the notion that the treatment primarily affected whether people gave, rather than how much they gave.\nTo visualize this, we plot histograms of donation amounts among donors, separated by treatment status. Both distributions are highly right-skewed. The mean donation is visually indicated by a red dashed line in each plot, showing similar average levels.\nThese findings imply that the matching grant mainly served as a behavioral nudge to increase participation, rather than changing the generosity of individual donors. The treatment coefficient in the restricted sample cannot be interpreted causally, since it conditions on post-treatment behavior (i.e., giving)."
  },
  {
    "objectID": "projects/HW1/index.html#simulation-experiment",
    "href": "projects/HW1/index.html#simulation-experiment",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Simulation Experiment",
    "text": "Simulation Experiment\nAs a reminder of how the t-statistic “works,” in this section I use simulation to demonstrate the Law of Large Numbers and the Central Limit Theorem.\nSuppose the true distribution of respondents who do not get a charitable donation match is Bernoulli with probability p=0.018 that a donation is made.\nFurther suppose that the true distribution of respondents who do get a charitable donation match of any size is Bernoulli with probability p=0.022 that a donation is made.\n\nLaw of Large Numbers\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nnp.random.seed(42)\n\n# 10000 draws for each group\nn = 10000\ncontrol = np.random.binomial(1, 0.018, n)\ntreatment = np.random.binomial(1, 0.022, n)\n\ndiffs = treatment - control\ncumulative_avg = np.cumsum(diffs) / np.arange(1, n + 1)\n\n# Plot\nplt.figure(figsize=(10, 5))\nplt.plot(cumulative_avg, label=\"Cumulative average\")\nplt.axhline(0.004, color='red', linestyle='--', label=\"True diff (0.022 - 0.018)\")\nplt.title(\"LLN Simulation: Cumulative Avg of Differences\")\nplt.xlabel(\"Simulation draws\")\nplt.ylabel(\"Cumulative average difference\")\nplt.legend()\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\n\n\nCentral Limit Theorem\n\nsample_sizes = [50, 200, 500, 1000]\nplt.figure(figsize=(12, 8))\n\nfor i, n in enumerate(sample_sizes):\n    means = []\n    for _ in range(1000):\n        c = np.random.binomial(1, 0.018, n)\n        t = np.random.binomial(1, 0.022, n)\n        means.append(t.mean() - c.mean())\n    \n    plt.subplot(2, 2, i+1)\n    plt.hist(means, bins=30, edgecolor='black')\n    plt.axvline(0, color='red', linestyle='--')\n    plt.title(f\"CLT: Sample Size = {n}\")\n    plt.xlabel(\"Mean Difference\")\n    plt.ylabel(\"Frequency\")\n\nplt.tight_layout()\nplt.suptitle(\"CLT Simulation: Sampling Distributions\", y=1.02)\nplt.show()\n\n\n\n\n\n\n\n\n\n\nSimulation Experiment\nTo illustrate the mechanics of the t-statistic and reinforce key statistical concepts, we conduct simulations that demonstrate the Law of Large Numbers (LLN) and the Central Limit Theorem (CLT).\n\nLaw of Large Numbers\nWe simulate 10,000 draws from two Bernoulli distributions: one representing the control group with probability 0.018 of giving, and one representing the treatment group with probability 0.022. At each iteration, we compute the difference in outcomes and plot the cumulative average of these differences.\nAs expected, the cumulative average converges toward the true difference in means (0.004). This visualizes the Law of Large Numbers, showing how repeated random samples stabilize around the population parameter.\n\n\nCentral Limit Theorem\nWe simulate 1000 differences in sample means between treatment and control groups at four different sample sizes: 50, 200, 500, and 1000. For each simulation, we draw n observations from each group and compute the average difference.\nThe resulting histograms clearly show that as sample size increases, the distribution of sample mean differences becomes narrower and more symmetric around the true value. At n = 1000, the distribution is nearly normal. These results validate the Central Limit Theorem, which states that the sampling distribution of the sample mean approaches normality as the sample size increases—even when the underlying distribution is Bernoulli.\nTogether, these simulations highlight the theoretical foundations that support our statistical inferences throughout this experiment."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "HaoxuanLi",
    "section": "",
    "text": "Welcome to my website!"
  },
  {
    "objectID": "projects/HW2/index.html",
    "href": "projects/HW2/index.html",
    "title": "Poisson Regression Examples",
    "section": "",
    "text": "Blueprinty is a small firm that makes software for developing blueprints specifically for submitting patent applications to the US patent office. Their marketing team would like to make the claim that patent applicants using Blueprinty’s software are more successful in getting their patent applications approved. Ideal data to study such an effect might include the success rate of patent applications before using Blueprinty’s software and after using it. Unfortunately, such data is not available.\nHowever, Blueprinty has collected data on 1,500 mature (non-startup) engineering firms. The data include each firm’s number of patents awarded over the last 5 years, regional location, age since incorporation, and whether or not the firm uses Blueprinty’s software. The marketing team would like to use this data to make the claim that firms using Blueprinty’s software are more successful in getting their patent applications approved.\n\n\n\n\nimport pandas as pd\ndf = pd.read_csv(\"C:\\\\Users\\\\ASUS\\\\Downloads\\\\blueprinty.csv\")\ndf.head()\n\n\n\n\n\n\n\n\npatents\nregion\nage\niscustomer\n\n\n\n\n0\n0\nMidwest\n32.5\n0\n\n\n1\n3\nSouthwest\n37.5\n0\n\n\n2\n4\nNorthwest\n27.0\n1\n\n\n3\n3\nNortheast\n24.5\n0\n\n\n4\n3\nSouthwest\n37.0\n0\n\n\n\n\n\n\n\n\n\n\n\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set(style=\"whitegrid\")\nimport matplotlib.pyplot as plt\n# Histogram of patent counts by customer status\nplt.figure(figsize=(10, 6))\nsns.histplot(data=df, x=\"patents\", hue=\"iscustomer\", kde=False, bins=30, element=\"step\", stat=\"density\", common_norm=False)\nplt.title(\"Histogram of Patent Counts by Customer Status\")\nplt.xlabel(\"Number of Patents\")\nplt.ylabel(\"Density\")\nplt.legend(title=\"Is Customer\")\nplt.show()\n\nC:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_73420\\598583040.py:11: UserWarning: No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n  plt.legend(title=\"Is Customer\")\n\n\n\n\n\n\n\n\n\n\n# Summary statistics: mean, std, count\ndf.groupby(\"iscustomer\")[\"patents\"].agg([\"mean\", \"std\", \"count\"])\n\n\n\n\n\n\n\n\nmean\nstd\ncount\n\n\niscustomer\n\n\n\n\n\n\n\n0\n3.473013\n2.225060\n1019\n\n\n1\n4.133056\n2.546846\n481\n\n\n\n\n\n\n\nBlueprinty customers are not selected at random. It may be important to account for systematic differences in the age and regional location of customers vs non-customers.\nWe begin by exploring the distribution of patent counts by customer status. As shown in the histogram above, firms that use Blueprinty’s software tend to have a slightly higher number of patents.\nThis pattern becomes more apparent when visualized.\nThe summary statistics support this: the average patent count for non-customers is 3.47, while it is 4.13 for customers. Although the distributions overlap substantially, Blueprinty customers appear to have heavier tails and slightly greater variance in patent production.\nThis preliminary evidence is consistent with the marketing team’s hypothesis that customers using Blueprinty software may be more productive in securing patents. However, other confounding factors (e.g., firm age and region) may also be driving these differences. We next examine those factors.\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Region distribution by customer status\nplt.figure(figsize=(10, 5))\nsns.countplot(data=df, x=\"region\", hue=\"iscustomer\")\nplt.title(\"Region Distribution by Customer Status\")\nplt.xlabel(\"Region\")\nplt.ylabel(\"Number of Firms\")\nplt.legend(title=\"Is Customer\")\nplt.xticks(rotation=45)\nplt.show()\n\n\n\n\n\n\n\n\n\n# Age distribution by customer status (KDE)\nplt.figure(figsize=(10, 6))\nsns.kdeplot(data=df, x=\"age\", hue=\"iscustomer\", fill=True, common_norm=False, alpha=0.5)\nplt.title(\"Firm Age Distribution by Customer Status\")\nplt.xlabel(\"Years Since Incorporation\")\nplt.ylabel(\"Density\")\nplt.legend(title=\"Is Customer\")\nplt.show()\n\nC:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_73420\\1229093569.py:7: UserWarning: No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n  plt.legend(title=\"Is Customer\")\n\n\n\n\n\n\n\n\n\nWe next examine whether Blueprinty customers differ from non-customers in their regional and age profiles.\nThe bar chart above shows noticeable variation in region distribution by customer status. For example, the Northeast region contains a disproportionately large number of Blueprinty customers, whereas Southwest and Midwest regions have relatively fewer. This suggests that firms in some regions may be more likely to adopt Blueprinty software, possibly due to regional innovation ecosystems, network effects, or marketing exposure.\nThe density plot of firm age also shows modest differences. While the two groups are broadly similar, Blueprinty customers appear to be slightly older on average, with a heavier tail toward longer-established firms. This could imply that mature firms are more inclined to use such specialized software tools.\nTogether, these findings underscore the importance of controlling for region and firm age in any causal analysis of software use and patent output. We now turn to Poisson regression to formally assess this relationship.\n\n\n\nSince our outcome variable of interest can only be small integer values per a set unit of time, we can use a Poisson density to model the number of patents awarded to each engineering firm over the last 5 years. We start by estimating a simple Poisson model via Maximum Likelihood.\nLet ( Y_1, Y_2, , Y_n () ), with probability mass function:\n[ f(Y_i ) = ]\nAssuming the observations are independent, the likelihood function is:\n[ L() = _{i=1}^{n} ]\nTaking the logarithm gives the log-likelihood function:\n[ L() = _{i=1}^{n} ]\nThis log-likelihood will be maximized to find the MLE of ().\ntodo: Code the likelihood (or log-likelihood) function for the Poisson model. This is a function of lambda and Y. For example:\npoisson_loglikelihood &lt;- function(lambda, Y){\n   ...\n}\n\nimport numpy as np\n\n# Define the log-likelihood function for Poisson(λ) given observed data Y\ndef poisson_log_likelihood(lmbda, y_vals):\n    if lmbda &lt;= 0:\n        return -np.inf  # log(λ) undefined for λ ≤ 0\n    return np.sum(y_vals * np.log(lmbda) - lmbda - np.log(np.math.factorial(y_vals)))\n\n\nfrom scipy.special import gammaln\n\ndef poisson_log_likelihood(lmbda, y_vals):\n    if lmbda &lt;= 0:\n        return -np.inf\n    return np.sum(y_vals * np.log(lmbda) - lmbda - gammaln(y_vals + 1))\n\n\nimport matplotlib.pyplot as plt\n\n# Use all patent counts as data\ny_vals = df[\"patents\"].values\n\n# Try lambda values from 0.1 to 10\nlambda_vals = np.linspace(0.1, 10, 200)\nlog_liks = [poisson_log_likelihood(lmbda, y_vals) for lmbda in lambda_vals]\n\n# Plot\nplt.figure(figsize=(8, 5))\nplt.plot(lambda_vals, log_liks, color='blue')\nplt.title(\"Log-Likelihood of Poisson Model\")\nplt.xlabel(\"Lambda\")\nplt.ylabel(\"Log-Likelihood\")\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\nTo confirm the intuition behind MLE for a Poisson model, we can take the derivative of the log-likelihood with respect to ():\n[ L() = {i=1}^{n} ( - 1 ) = {i=1}^{n} Y_i - n ]\nSetting this equal to 0 and solving:\n[ Y_i = n = Y_i = {Y} ]\nThis confirms that the MLE for () in a Poisson distribution is simply the sample mean.\ntodo: Find the MLE by optimizing your likelihood function with optim() in R or sp.optimize() in Python.\n\nfrom scipy.optimize import minimize\n\n# Convert log-likelihood to a negative form for minimization\nneg_log_likelihood = lambda lmbda: -poisson_log_likelihood(lmbda[0], df[\"patents\"].values)\n\n# Run the optimizer\nresult = minimize(neg_log_likelihood, x0=[2.0], bounds=[(1e-5, None)])\n\n# Get the estimated lambda (MLE)\nlambda_mle = result.x[0]\nlambda_mle\n\nnp.float64(3.6846666035175017)\n\n\nWe used scipy.optimize.minimize() to find the value of () that maximizes the Poisson log-likelihood function. The optimizer returned:\n[ = 3.68 ]\nThis result matches the sample average of the patent counts in our dataset, which is also approximately 3.68. This confirms the theoretical result that the MLE for () in a Poisson model is simply the mean of the observed values.\n\n\n\nNext, we extend our simple Poisson model to a Poisson Regression Model such that \\(Y_i = \\text{Poisson}(\\lambda_i)\\) where \\(\\lambda_i = \\exp(X_i'\\beta)\\). The interpretation is that the success rate of patent awards is not constant across all firms (\\(\\lambda\\)) but rather is a function of firm characteristics \\(X_i\\). Specifically, we will use the covariates age, age squared, region, and whether the firm is a customer of Blueprinty.\n\ndef poisson_regression_loglik(beta, X, y):\n    beta = np.asarray(beta).reshape(-1)\n    y = np.asarray(y).astype(float)\n    eta = X @ beta\n    lambdas = np.exp(eta)\n    log_lik = np.sum(y * eta - lambdas - gammaln(y + 1))\n    return -log_lik\n\n\nimport statsmodels.api as sm\nimport pandas as pd\n\n\ndf[\"age2\"] = df[\"age\"] ** 2\nregion_dummies = pd.get_dummies(df[\"region\"], prefix=\"region\", drop_first=True)\n\nX = pd.concat([\n    df[[\"iscustomer\", \"age\", \"age2\"]],\n    region_dummies\n], axis=1)\n\nX = sm.add_constant(X)\nX = X.astype(float) \ny = df[\"patents\"]\npoisson_model = sm.GLM(y, X, family=sm.families.Poisson()).fit()\nprint(poisson_model.summary())\n\n                 Generalized Linear Model Regression Results                  \n==============================================================================\nDep. Variable:                patents   No. Observations:                 1500\nModel:                            GLM   Df Residuals:                     1492\nModel Family:                 Poisson   Df Model:                            7\nLink Function:                    Log   Scale:                          1.0000\nMethod:                          IRLS   Log-Likelihood:                -3258.1\nDate:                Wed, 07 May 2025   Deviance:                       2143.3\nTime:                        23:35:19   Pearson chi2:                 2.07e+03\nNo. Iterations:                     5   Pseudo R-squ. (CS):             0.1360\nCovariance Type:            nonrobust                                         \n====================================================================================\n                       coef    std err          z      P&gt;|z|      [0.025      0.975]\n------------------------------------------------------------------------------------\nconst               -0.5089      0.183     -2.778      0.005      -0.868      -0.150\niscustomer           0.2076      0.031      6.719      0.000       0.147       0.268\nage                  0.1486      0.014     10.716      0.000       0.121       0.176\nage2                -0.0030      0.000    -11.513      0.000      -0.003      -0.002\nregion_Northeast     0.0292      0.044      0.669      0.504      -0.056       0.115\nregion_Northwest    -0.0176      0.054     -0.327      0.744      -0.123       0.088\nregion_South         0.0566      0.053      1.074      0.283      -0.047       0.160\nregion_Southwest     0.0506      0.047      1.072      0.284      -0.042       0.143\n====================================================================================\n\n\n\ncoefs = poisson_model.params\nses = poisson_model.bse\npvals = poisson_model.pvalues\nirr = np.exp(coefs)\ndef significance_stars(p):\n    if p &lt; 0.001:\n        return \"***\"\n    elif p &lt; 0.01:\n        return \"**\"\n    elif p &lt; 0.05:\n        return \"*\"\n    elif p &lt; 0.1:\n        return \".\"\n    else:\n        return \"\"\n\nstars = pvals.apply(significance_stars)\nsummary_table = pd.DataFrame({\n    \"Variable\": coefs.index,\n    \"Coef.\": coefs.round(4),\n    \"Std.Err\": ses.round(4),\n    \"p-value\": pvals.round(4),\n    \"IRR\": irr.round(4),\n    \"Signif\": stars\n})\n\nsummary_table\n\n\n\n\n\n\n\n\nVariable\nCoef.\nStd.Err\np-value\nIRR\nSignif\n\n\n\n\nconst\nconst\n-0.5089\n0.1832\n0.0055\n0.6011\n**\n\n\niscustomer\niscustomer\n0.2076\n0.0309\n0.0000\n1.2307\n***\n\n\nage\nage\n0.1486\n0.0139\n0.0000\n1.1602\n***\n\n\nage2\nage2\n-0.0030\n0.0003\n0.0000\n0.9970\n***\n\n\nregion_Northeast\nregion_Northeast\n0.0292\n0.0436\n0.5037\n1.0296\n\n\n\nregion_Northwest\nregion_Northwest\n-0.0176\n0.0538\n0.7438\n0.9826\n\n\n\nregion_South\nregion_South\n0.0566\n0.0527\n0.2828\n1.0582\n\n\n\nregion_Southwest\nregion_Southwest\n0.0506\n0.0472\n0.2839\n1.0519\n\n\n\n\n\n\n\n\nWe estimated a Poisson regression model to examine whether firms that use Blueprinty software are more successful in obtaining patents. The model includes firm characteristics such as age, age squared, and region, along with a binary indicator for whether the firm is a Blueprinty customer. The coefficient on iscustomer is positive and highly statistically significant (p &lt; 0.001), with an incident rate ratio (IRR) of 1.23. This suggests that, holding other variables constant, The effect of age is also strong and positive, but the negative coefficient on age² suggests diminishing returns: as firms grow older, their patent output increases, but at a decreasing rate. Regional differences appear not to be statistically significant after accounting for age and customer status, as none of the region dummy variables show significant effects.\nWe estimated the Poisson regression model using Python’s statsmodels.GLM() function with a log link and Poisson family, as suggested. This is equivalent to R’s glm(..., family = poisson) and provides consistent MLE estimates, standard errors, and significance tests.\n\nX0 = X.copy()\nX1 = X.copy()\n\nX0[\"iscustomer\"] = 0\nX1[\"iscustomer\"] = 1\ny_pred_0 = poisson_model.predict(X0)\ny_pred_1 = poisson_model.predict(X1)\n\ndiff = y_pred_1 - y_pred_0\nate = diff.mean()\n\nprint(f\"Average predicted effect of Blueprinty = {ate:.3f} additional patents per firm.\")\n\nAverage predicted effect of Blueprinty = 0.793 additional patents per firm.\n\n\nTo more concretely interpret the effect of Blueprinty’s software on patent outcomes, we conducted a counterfactual simulation.\nUsing our fitted Poisson regression model, we predicted the expected number of patents for each firm under two scenarios:\n\nScenario 1: All firms are non-customers (iscustomer = 0)\nScenario 2: All firms are Blueprinty customers (iscustomer = 1)\n\nWe then computed the difference in predicted patent counts for each firm and took the average across all firms.\nThe result suggests that, on average, a firm would be expected to receive 0.793 more patents over a 5-year period if it were a Blueprinty customer, holding other variables constant.\nThis provides a clear, interpretable estimate of Blueprinty’s impact and supports the marketing team’s claim with a data-driven justification."
  },
  {
    "objectID": "projects/HW2/index.html#blueprinty-case-study",
    "href": "projects/HW2/index.html#blueprinty-case-study",
    "title": "Poisson Regression Examples",
    "section": "",
    "text": "Blueprinty is a small firm that makes software for developing blueprints specifically for submitting patent applications to the US patent office. Their marketing team would like to make the claim that patent applicants using Blueprinty’s software are more successful in getting their patent applications approved. Ideal data to study such an effect might include the success rate of patent applications before using Blueprinty’s software and after using it. Unfortunately, such data is not available.\nHowever, Blueprinty has collected data on 1,500 mature (non-startup) engineering firms. The data include each firm’s number of patents awarded over the last 5 years, regional location, age since incorporation, and whether or not the firm uses Blueprinty’s software. The marketing team would like to use this data to make the claim that firms using Blueprinty’s software are more successful in getting their patent applications approved.\n\n\n\n\nimport pandas as pd\ndf = pd.read_csv(\"C:\\\\Users\\\\ASUS\\\\Downloads\\\\blueprinty.csv\")\ndf.head()\n\n\n\n\n\n\n\n\npatents\nregion\nage\niscustomer\n\n\n\n\n0\n0\nMidwest\n32.5\n0\n\n\n1\n3\nSouthwest\n37.5\n0\n\n\n2\n4\nNorthwest\n27.0\n1\n\n\n3\n3\nNortheast\n24.5\n0\n\n\n4\n3\nSouthwest\n37.0\n0\n\n\n\n\n\n\n\n\n\n\n\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set(style=\"whitegrid\")\nimport matplotlib.pyplot as plt\n# Histogram of patent counts by customer status\nplt.figure(figsize=(10, 6))\nsns.histplot(data=df, x=\"patents\", hue=\"iscustomer\", kde=False, bins=30, element=\"step\", stat=\"density\", common_norm=False)\nplt.title(\"Histogram of Patent Counts by Customer Status\")\nplt.xlabel(\"Number of Patents\")\nplt.ylabel(\"Density\")\nplt.legend(title=\"Is Customer\")\nplt.show()\n\nC:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_73420\\598583040.py:11: UserWarning: No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n  plt.legend(title=\"Is Customer\")\n\n\n\n\n\n\n\n\n\n\n# Summary statistics: mean, std, count\ndf.groupby(\"iscustomer\")[\"patents\"].agg([\"mean\", \"std\", \"count\"])\n\n\n\n\n\n\n\n\nmean\nstd\ncount\n\n\niscustomer\n\n\n\n\n\n\n\n0\n3.473013\n2.225060\n1019\n\n\n1\n4.133056\n2.546846\n481\n\n\n\n\n\n\n\nBlueprinty customers are not selected at random. It may be important to account for systematic differences in the age and regional location of customers vs non-customers.\nWe begin by exploring the distribution of patent counts by customer status. As shown in the histogram above, firms that use Blueprinty’s software tend to have a slightly higher number of patents.\nThis pattern becomes more apparent when visualized.\nThe summary statistics support this: the average patent count for non-customers is 3.47, while it is 4.13 for customers. Although the distributions overlap substantially, Blueprinty customers appear to have heavier tails and slightly greater variance in patent production.\nThis preliminary evidence is consistent with the marketing team’s hypothesis that customers using Blueprinty software may be more productive in securing patents. However, other confounding factors (e.g., firm age and region) may also be driving these differences. We next examine those factors.\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Region distribution by customer status\nplt.figure(figsize=(10, 5))\nsns.countplot(data=df, x=\"region\", hue=\"iscustomer\")\nplt.title(\"Region Distribution by Customer Status\")\nplt.xlabel(\"Region\")\nplt.ylabel(\"Number of Firms\")\nplt.legend(title=\"Is Customer\")\nplt.xticks(rotation=45)\nplt.show()\n\n\n\n\n\n\n\n\n\n# Age distribution by customer status (KDE)\nplt.figure(figsize=(10, 6))\nsns.kdeplot(data=df, x=\"age\", hue=\"iscustomer\", fill=True, common_norm=False, alpha=0.5)\nplt.title(\"Firm Age Distribution by Customer Status\")\nplt.xlabel(\"Years Since Incorporation\")\nplt.ylabel(\"Density\")\nplt.legend(title=\"Is Customer\")\nplt.show()\n\nC:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_73420\\1229093569.py:7: UserWarning: No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n  plt.legend(title=\"Is Customer\")\n\n\n\n\n\n\n\n\n\nWe next examine whether Blueprinty customers differ from non-customers in their regional and age profiles.\nThe bar chart above shows noticeable variation in region distribution by customer status. For example, the Northeast region contains a disproportionately large number of Blueprinty customers, whereas Southwest and Midwest regions have relatively fewer. This suggests that firms in some regions may be more likely to adopt Blueprinty software, possibly due to regional innovation ecosystems, network effects, or marketing exposure.\nThe density plot of firm age also shows modest differences. While the two groups are broadly similar, Blueprinty customers appear to be slightly older on average, with a heavier tail toward longer-established firms. This could imply that mature firms are more inclined to use such specialized software tools.\nTogether, these findings underscore the importance of controlling for region and firm age in any causal analysis of software use and patent output. We now turn to Poisson regression to formally assess this relationship.\n\n\n\nSince our outcome variable of interest can only be small integer values per a set unit of time, we can use a Poisson density to model the number of patents awarded to each engineering firm over the last 5 years. We start by estimating a simple Poisson model via Maximum Likelihood.\nLet ( Y_1, Y_2, , Y_n () ), with probability mass function:\n[ f(Y_i ) = ]\nAssuming the observations are independent, the likelihood function is:\n[ L() = _{i=1}^{n} ]\nTaking the logarithm gives the log-likelihood function:\n[ L() = _{i=1}^{n} ]\nThis log-likelihood will be maximized to find the MLE of ().\ntodo: Code the likelihood (or log-likelihood) function for the Poisson model. This is a function of lambda and Y. For example:\npoisson_loglikelihood &lt;- function(lambda, Y){\n   ...\n}\n\nimport numpy as np\n\n# Define the log-likelihood function for Poisson(λ) given observed data Y\ndef poisson_log_likelihood(lmbda, y_vals):\n    if lmbda &lt;= 0:\n        return -np.inf  # log(λ) undefined for λ ≤ 0\n    return np.sum(y_vals * np.log(lmbda) - lmbda - np.log(np.math.factorial(y_vals)))\n\n\nfrom scipy.special import gammaln\n\ndef poisson_log_likelihood(lmbda, y_vals):\n    if lmbda &lt;= 0:\n        return -np.inf\n    return np.sum(y_vals * np.log(lmbda) - lmbda - gammaln(y_vals + 1))\n\n\nimport matplotlib.pyplot as plt\n\n# Use all patent counts as data\ny_vals = df[\"patents\"].values\n\n# Try lambda values from 0.1 to 10\nlambda_vals = np.linspace(0.1, 10, 200)\nlog_liks = [poisson_log_likelihood(lmbda, y_vals) for lmbda in lambda_vals]\n\n# Plot\nplt.figure(figsize=(8, 5))\nplt.plot(lambda_vals, log_liks, color='blue')\nplt.title(\"Log-Likelihood of Poisson Model\")\nplt.xlabel(\"Lambda\")\nplt.ylabel(\"Log-Likelihood\")\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\nTo confirm the intuition behind MLE for a Poisson model, we can take the derivative of the log-likelihood with respect to ():\n[ L() = {i=1}^{n} ( - 1 ) = {i=1}^{n} Y_i - n ]\nSetting this equal to 0 and solving:\n[ Y_i = n = Y_i = {Y} ]\nThis confirms that the MLE for () in a Poisson distribution is simply the sample mean.\ntodo: Find the MLE by optimizing your likelihood function with optim() in R or sp.optimize() in Python.\n\nfrom scipy.optimize import minimize\n\n# Convert log-likelihood to a negative form for minimization\nneg_log_likelihood = lambda lmbda: -poisson_log_likelihood(lmbda[0], df[\"patents\"].values)\n\n# Run the optimizer\nresult = minimize(neg_log_likelihood, x0=[2.0], bounds=[(1e-5, None)])\n\n# Get the estimated lambda (MLE)\nlambda_mle = result.x[0]\nlambda_mle\n\nnp.float64(3.6846666035175017)\n\n\nWe used scipy.optimize.minimize() to find the value of () that maximizes the Poisson log-likelihood function. The optimizer returned:\n[ = 3.68 ]\nThis result matches the sample average of the patent counts in our dataset, which is also approximately 3.68. This confirms the theoretical result that the MLE for () in a Poisson model is simply the mean of the observed values.\n\n\n\nNext, we extend our simple Poisson model to a Poisson Regression Model such that \\(Y_i = \\text{Poisson}(\\lambda_i)\\) where \\(\\lambda_i = \\exp(X_i'\\beta)\\). The interpretation is that the success rate of patent awards is not constant across all firms (\\(\\lambda\\)) but rather is a function of firm characteristics \\(X_i\\). Specifically, we will use the covariates age, age squared, region, and whether the firm is a customer of Blueprinty.\n\ndef poisson_regression_loglik(beta, X, y):\n    beta = np.asarray(beta).reshape(-1)\n    y = np.asarray(y).astype(float)\n    eta = X @ beta\n    lambdas = np.exp(eta)\n    log_lik = np.sum(y * eta - lambdas - gammaln(y + 1))\n    return -log_lik\n\n\nimport statsmodels.api as sm\nimport pandas as pd\n\n\ndf[\"age2\"] = df[\"age\"] ** 2\nregion_dummies = pd.get_dummies(df[\"region\"], prefix=\"region\", drop_first=True)\n\nX = pd.concat([\n    df[[\"iscustomer\", \"age\", \"age2\"]],\n    region_dummies\n], axis=1)\n\nX = sm.add_constant(X)\nX = X.astype(float) \ny = df[\"patents\"]\npoisson_model = sm.GLM(y, X, family=sm.families.Poisson()).fit()\nprint(poisson_model.summary())\n\n                 Generalized Linear Model Regression Results                  \n==============================================================================\nDep. Variable:                patents   No. Observations:                 1500\nModel:                            GLM   Df Residuals:                     1492\nModel Family:                 Poisson   Df Model:                            7\nLink Function:                    Log   Scale:                          1.0000\nMethod:                          IRLS   Log-Likelihood:                -3258.1\nDate:                Wed, 07 May 2025   Deviance:                       2143.3\nTime:                        23:35:19   Pearson chi2:                 2.07e+03\nNo. Iterations:                     5   Pseudo R-squ. (CS):             0.1360\nCovariance Type:            nonrobust                                         \n====================================================================================\n                       coef    std err          z      P&gt;|z|      [0.025      0.975]\n------------------------------------------------------------------------------------\nconst               -0.5089      0.183     -2.778      0.005      -0.868      -0.150\niscustomer           0.2076      0.031      6.719      0.000       0.147       0.268\nage                  0.1486      0.014     10.716      0.000       0.121       0.176\nage2                -0.0030      0.000    -11.513      0.000      -0.003      -0.002\nregion_Northeast     0.0292      0.044      0.669      0.504      -0.056       0.115\nregion_Northwest    -0.0176      0.054     -0.327      0.744      -0.123       0.088\nregion_South         0.0566      0.053      1.074      0.283      -0.047       0.160\nregion_Southwest     0.0506      0.047      1.072      0.284      -0.042       0.143\n====================================================================================\n\n\n\ncoefs = poisson_model.params\nses = poisson_model.bse\npvals = poisson_model.pvalues\nirr = np.exp(coefs)\ndef significance_stars(p):\n    if p &lt; 0.001:\n        return \"***\"\n    elif p &lt; 0.01:\n        return \"**\"\n    elif p &lt; 0.05:\n        return \"*\"\n    elif p &lt; 0.1:\n        return \".\"\n    else:\n        return \"\"\n\nstars = pvals.apply(significance_stars)\nsummary_table = pd.DataFrame({\n    \"Variable\": coefs.index,\n    \"Coef.\": coefs.round(4),\n    \"Std.Err\": ses.round(4),\n    \"p-value\": pvals.round(4),\n    \"IRR\": irr.round(4),\n    \"Signif\": stars\n})\n\nsummary_table\n\n\n\n\n\n\n\n\nVariable\nCoef.\nStd.Err\np-value\nIRR\nSignif\n\n\n\n\nconst\nconst\n-0.5089\n0.1832\n0.0055\n0.6011\n**\n\n\niscustomer\niscustomer\n0.2076\n0.0309\n0.0000\n1.2307\n***\n\n\nage\nage\n0.1486\n0.0139\n0.0000\n1.1602\n***\n\n\nage2\nage2\n-0.0030\n0.0003\n0.0000\n0.9970\n***\n\n\nregion_Northeast\nregion_Northeast\n0.0292\n0.0436\n0.5037\n1.0296\n\n\n\nregion_Northwest\nregion_Northwest\n-0.0176\n0.0538\n0.7438\n0.9826\n\n\n\nregion_South\nregion_South\n0.0566\n0.0527\n0.2828\n1.0582\n\n\n\nregion_Southwest\nregion_Southwest\n0.0506\n0.0472\n0.2839\n1.0519\n\n\n\n\n\n\n\n\nWe estimated a Poisson regression model to examine whether firms that use Blueprinty software are more successful in obtaining patents. The model includes firm characteristics such as age, age squared, and region, along with a binary indicator for whether the firm is a Blueprinty customer. The coefficient on iscustomer is positive and highly statistically significant (p &lt; 0.001), with an incident rate ratio (IRR) of 1.23. This suggests that, holding other variables constant, The effect of age is also strong and positive, but the negative coefficient on age² suggests diminishing returns: as firms grow older, their patent output increases, but at a decreasing rate. Regional differences appear not to be statistically significant after accounting for age and customer status, as none of the region dummy variables show significant effects.\nWe estimated the Poisson regression model using Python’s statsmodels.GLM() function with a log link and Poisson family, as suggested. This is equivalent to R’s glm(..., family = poisson) and provides consistent MLE estimates, standard errors, and significance tests.\n\nX0 = X.copy()\nX1 = X.copy()\n\nX0[\"iscustomer\"] = 0\nX1[\"iscustomer\"] = 1\ny_pred_0 = poisson_model.predict(X0)\ny_pred_1 = poisson_model.predict(X1)\n\ndiff = y_pred_1 - y_pred_0\nate = diff.mean()\n\nprint(f\"Average predicted effect of Blueprinty = {ate:.3f} additional patents per firm.\")\n\nAverage predicted effect of Blueprinty = 0.793 additional patents per firm.\n\n\nTo more concretely interpret the effect of Blueprinty’s software on patent outcomes, we conducted a counterfactual simulation.\nUsing our fitted Poisson regression model, we predicted the expected number of patents for each firm under two scenarios:\n\nScenario 1: All firms are non-customers (iscustomer = 0)\nScenario 2: All firms are Blueprinty customers (iscustomer = 1)\n\nWe then computed the difference in predicted patent counts for each firm and took the average across all firms.\nThe result suggests that, on average, a firm would be expected to receive 0.793 more patents over a 5-year period if it were a Blueprinty customer, holding other variables constant.\nThis provides a clear, interpretable estimate of Blueprinty’s impact and supports the marketing team’s claim with a data-driven justification."
  },
  {
    "objectID": "projects/HW2/index.html#airbnb-case-study",
    "href": "projects/HW2/index.html#airbnb-case-study",
    "title": "Poisson Regression Examples",
    "section": "AirBnB Case Study",
    "text": "AirBnB Case Study\n\nIntroduction\nAirBnB is a popular platform for booking short-term rentals. In March 2017, students Annika Awad, Evan Lebo, and Anna Linden scraped of 40,000 Airbnb listings from New York City. The data include the following variables:\n\n\n\n\n\n\nVariable Definitions\n\n\n\n\n\n- `id` = unique ID number for each unit\n- `last_scraped` = date when information scraped\n- `host_since` = date when host first listed the unit on Airbnb\n- `days` = `last_scraped` - `host_since` = number of days the unit has been listed\n- `room_type` = Entire home/apt., Private room, or Shared room\n- `bathrooms` = number of bathrooms\n- `bedrooms` = number of bedrooms\n- `price` = price per night (dollars)\n- `number_of_reviews` = number of reviews for the unit on Airbnb\n- `review_scores_cleanliness` = a cleanliness score from reviews (1-10)\n- `review_scores_location` = a \"quality of location\" score from reviews (1-10)\n- `review_scores_value` = a \"quality of value\" score from reviews (1-10)\n- `instant_bookable` = \"t\" if instantly bookable, \"f\" if not\n\n\n\n\nimport pandas as pd\nairbnb = pd.read_csv(\"C:\\\\Users\\\\ASUS\\\\Downloads\\\\airbnb.csv\") \nairbnb.info()\nairbnb.head()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 40628 entries, 0 to 40627\nData columns (total 14 columns):\n #   Column                     Non-Null Count  Dtype  \n---  ------                     --------------  -----  \n 0   Unnamed: 0                 40628 non-null  int64  \n 1   id                         40628 non-null  int64  \n 2   days                       40628 non-null  int64  \n 3   last_scraped               40628 non-null  object \n 4   host_since                 40593 non-null  object \n 5   room_type                  40628 non-null  object \n 6   bathrooms                  40468 non-null  float64\n 7   bedrooms                   40552 non-null  float64\n 8   price                      40628 non-null  int64  \n 9   number_of_reviews          40628 non-null  int64  \n 10  review_scores_cleanliness  30433 non-null  float64\n 11  review_scores_location     30374 non-null  float64\n 12  review_scores_value        30372 non-null  float64\n 13  instant_bookable           40628 non-null  object \ndtypes: float64(5), int64(5), object(4)\nmemory usage: 4.3+ MB\n\n\n\n\n\n\n\n\n\nUnnamed: 0\nid\ndays\nlast_scraped\nhost_since\nroom_type\nbathrooms\nbedrooms\nprice\nnumber_of_reviews\nreview_scores_cleanliness\nreview_scores_location\nreview_scores_value\ninstant_bookable\n\n\n\n\n0\n1\n2515\n3130\n4/2/2017\n9/6/2008\nPrivate room\n1.0\n1.0\n59\n150\n9.0\n9.0\n9.0\nf\n\n\n1\n2\n2595\n3127\n4/2/2017\n9/9/2008\nEntire home/apt\n1.0\n0.0\n230\n20\n9.0\n10.0\n9.0\nf\n\n\n2\n3\n3647\n3050\n4/2/2017\n11/25/2008\nPrivate room\n1.0\n1.0\n150\n0\nNaN\nNaN\nNaN\nf\n\n\n3\n4\n3831\n3038\n4/2/2017\n12/7/2008\nEntire home/apt\n1.0\n1.0\n89\n116\n9.0\n9.0\n9.0\nf\n\n\n4\n5\n4611\n3012\n4/2/2017\n1/2/2009\nPrivate room\nNaN\n1.0\n39\n93\n9.0\n8.0\n9.0\nt\n\n\n\n\n\n\n\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nplt.figure(figsize=(8, 5))\nsns.histplot(airbnb[\"number_of_reviews\"], bins=10, kde=False)\nplt.title(\"Distribution of Number of Reviews\")\nplt.xlabel(\"Number of Reviews\")\nplt.ylabel(\"Count\")\nplt.show()\n\n\n\n\n\n\n\n\n\nvars_for_model = [\n    \"number_of_reviews\", \"days\", \"room_type\", \"price\",\n    \"review_scores_cleanliness\", \"review_scores_location\",\n    \"review_scores_value\", \"instant_bookable\"\n]\n\nairbnb_clean = airbnb[vars_for_model].dropna()\n\nairbnb_clean[\"instant_bookable\"] = airbnb_clean[\"instant_bookable\"].map({\"t\": 1, \"f\": 0})\n\nroom_dummies = pd.get_dummies(airbnb_clean[\"room_type\"], prefix=\"room\", drop_first=True)\n\n\nX_df = pd.concat([airbnb_clean.drop(columns=[\"room_type\"]), room_dummies], axis=1)\n\nX_df.head()\n\n\n\n\n\n\n\n\nnumber_of_reviews\ndays\nprice\nreview_scores_cleanliness\nreview_scores_location\nreview_scores_value\ninstant_bookable\nroom_Private room\nroom_Shared room\n\n\n\n\n0\n150\n3130\n59\n9.0\n9.0\n9.0\n0\nTrue\nFalse\n\n\n1\n20\n3127\n230\n9.0\n10.0\n9.0\n0\nFalse\nFalse\n\n\n3\n116\n3038\n89\n9.0\n9.0\n9.0\n0\nFalse\nFalse\n\n\n4\n93\n3012\n39\n9.0\n8.0\n9.0\n1\nTrue\nFalse\n\n\n5\n60\n2981\n212\n9.0\n9.0\n9.0\n0\nFalse\nFalse\n\n\n\n\n\n\n\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nplt.figure(figsize=(8, 5))\nsns.scatterplot(data=X_df, x=\"days\", y=\"number_of_reviews\", alpha=0.3)\nplt.title(\"Number of Reviews vs. Days Listed\")\nplt.xlabel(\"Days Listed on Airbnb\")\nplt.ylabel(\"Number of Reviews\")\nplt.show()\n\n\n\n\n\n\n\n\nWe begin by examining the relationship between the number of reviews and the number of days a listing has been active on Airbnb.\nA scatter plot of number_of_reviews against days (the time since the listing was first posted) shows a clear positive relationship: listings that have been on the platform longer tend to have more reviews. This is intuitive, as older listings have had more time to accumulate customer feedback.\nHowever, we also observe some extreme outliers, with days values exceeding 30,000 (i.e., over 80 years). These are likely data errors or artifacts from date calculations and should be removed before modeling. We propose restricting the dataset to listings with fewer than 5,000 days active (approximately 13 years) to ensure data quality.\nThis initial visualization confirms that days is a key variable in predicting the number of reviews and motivates its inclusion in the Poisson regression model.\n\nX_df_filtered = X_df[X_df[\"days\"] &lt; 5000]  \n\n\nsns.scatterplot(data=X_df_filtered, x=\"days\", y=\"number_of_reviews\", alpha=0.3)\nplt.title(\"Filtered: Number of Reviews vs. Days (&lt;5000)\")\nplt.show()\n\n\n\n\n\n\n\n\n\nimport statsmodels.api as sm\n\ny = X_df_filtered[\"number_of_reviews\"]\nX = sm.add_constant(X_df_filtered[\"days\"]) \n\npoisson_model = sm.GLM(y, X, family=sm.families.Poisson()).fit()\n\ncoefs = poisson_model.params\nses = poisson_model.bse\npvals = poisson_model.pvalues\nirr = np.exp(coefs)\nsummary_table = pd.DataFrame({\n    \"Variable\": coefs.index,\n    \"Coefficient\": coefs.values,\n    \"Std. Error\": ses.values,\n    \"p-value\": pvals.values,\n    \"IRR\": irr.values\n})\nsummary_table.round(4)\n\n\n\n\n\n\n\n\nVariable\nCoefficient\nStd. Error\np-value\nIRR\n\n\n\n\n0\nconst\n2.4616\n0.0028\n0.0\n11.7237\n\n\n1\ndays\n0.0005\n0.0000\n0.0\n1.0005\n\n\n\n\n\n\n\nTo examine the relationship between listing age and review volume, we modeled the number of reviews a listing received using a Poisson regression, with days (the number of days since the listing went live) as the sole predictor.\nThe table below summarizes the regression results:\nVariable Coefficient Std. Error p-value IRR Intercept 2.4616 0.0028 &lt;0.001 11.7237 Days 0.0005 0.0000 &lt;0.001 1.0005\nThe coefficient on days is positive and highly statistically significant. Interpreted as an incident rate ratio (IRR), each additional day a listing is online is associated with a 0.05% increase in the expected number of reviews. This suggests that listing duration is an important driver of review accumulation, as older listings naturally have more time to attract guests and feedback.\nThis simple model confirms the usefulness of days as a predictor and motivates its inclusion in more comprehensive models that incorporate additional listing characteristics.\n\nimport statsmodels.api as sm\n\ny = X_df_filtered[\"number_of_reviews\"]\n\nX_multi = X_df_filtered.drop(columns=[\"number_of_reviews\"])\n\nX_multi = sm.add_constant(X_multi)\n\nX_multi = X_multi.astype(float)\n\npoisson_full_model = sm.GLM(y, X_multi, family=sm.families.Poisson()).fit()\n\nprint(poisson_full_model.summary())\n\n                 Generalized Linear Model Regression Results                  \n==============================================================================\nDep. Variable:      number_of_reviews   No. Observations:                30325\nModel:                            GLM   Df Residuals:                    30316\nModel Family:                 Poisson   Df Model:                            8\nLink Function:                    Log   Scale:                          1.0000\nMethod:                          IRLS   Log-Likelihood:            -4.9535e+05\nDate:                Wed, 07 May 2025   Deviance:                   8.6847e+05\nTime:                        23:35:19   Pearson chi2:                 1.19e+06\nNo. Iterations:                     6   Pseudo R-squ. (CS):             0.9655\nCovariance Type:            nonrobust                                         \n=============================================================================================\n                                coef    std err          z      P&gt;|z|      [0.025      0.975]\n---------------------------------------------------------------------------------------------\nconst                         2.9260      0.016    183.233      0.000       2.895       2.957\ndays                          0.0005   1.84e-06    284.613      0.000       0.001       0.001\nprice                     -3.144e-05    7.5e-06     -4.191      0.000   -4.61e-05   -1.67e-05\nreview_scores_cleanliness     0.1109      0.002     73.536      0.000       0.108       0.114\nreview_scores_location       -0.0859      0.002    -53.815      0.000      -0.089      -0.083\nreview_scores_value          -0.0889      0.002    -48.336      0.000      -0.092      -0.085\ninstant_bookable              0.4598      0.003    158.119      0.000       0.454       0.465\nroom_Private room             0.0079      0.003      2.933      0.003       0.003       0.013\nroom_Shared room             -0.1243      0.009    -14.466      0.000      -0.141      -0.107\n=============================================================================================\n\n\n\nimport numpy as np\nimport pandas as pd\n\ncoefs = poisson_full_model.params\nses = poisson_full_model.bse\npvals = poisson_full_model.pvalues\nirr = np.exp(coefs)\n\nsummary_full = pd.DataFrame({\n    \"Variable\": coefs.index,\n    \"Coefficient\": coefs.values,\n    \"Std. Error\": ses.values,\n    \"p-value\": pvals.values,\n    \"IRR\": irr.values\n}).round(4)\n\nsummary_full\n\n\n\n\n\n\n\n\nVariable\nCoefficient\nStd. Error\np-value\nIRR\n\n\n\n\n0\nconst\n2.9260\n0.0160\n0.0000\n18.6536\n\n\n1\ndays\n0.0005\n0.0000\n0.0000\n1.0005\n\n\n2\nprice\n-0.0000\n0.0000\n0.0000\n1.0000\n\n\n3\nreview_scores_cleanliness\n0.1109\n0.0015\n0.0000\n1.1173\n\n\n4\nreview_scores_location\n-0.0859\n0.0016\n0.0000\n0.9177\n\n\n5\nreview_scores_value\n-0.0889\n0.0018\n0.0000\n0.9150\n\n\n6\ninstant_bookable\n0.4598\n0.0029\n0.0000\n1.5838\n\n\n7\nroom_Private room\n0.0079\n0.0027\n0.0034\n1.0079\n\n\n8\nroom_Shared room\n-0.1243\n0.0086\n0.0000\n0.8831\n\n\n\n\n\n\n\nWe extend our Poisson regression model to include additional covariates related to listing characteristics, including price, review scores, room type, and instant bookability.\nKey findings include:\n\ndays remains a highly significant and positive predictor of review count. Each extra day on the platform increases expected reviews by ~0.05% (IRR = 1.0005).\nprice has a small but significant negative coefficient, indicating that more expensive listings tend to get fewer reviews.\nreview_scores_cleanliness is positively associated with reviews (IRR &gt; 1), while review_scores_location and review_scores_value are negatively associated.\ninstant_bookable listings receive about 58% more reviews than those that are not (IRR ≈ 1.58).\nCompared to the baseline category (likely Entire home/apt), Shared rooms receive significantly fewer reviews (IRR ≈ 0.88), while Private rooms are not substantially different.\n\nThese results offer interpretable evidence that both listing age and features like review quality, price, and booking flexibility influence review counts."
  }
]